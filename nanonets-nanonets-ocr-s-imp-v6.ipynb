{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-14T01:02:47.488670Z",
     "iopub.status.busy": "2025-10-14T01:02:47.488428Z",
     "iopub.status.idle": "2025-10-14T01:02:54.181735Z",
     "shell.execute_reply": "2025-10-14T01:02:54.180741Z",
     "shell.execute_reply.started": "2025-10-14T01:02:47.488647Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gradio PyMuPDF\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T01:02:54.184367Z",
     "iopub.status.busy": "2025-10-14T01:02:54.184148Z",
     "iopub.status.idle": "2025-10-14T01:03:21.004986Z",
     "shell.execute_reply": "2025-10-14T01:03:21.004440Z",
     "shell.execute_reply.started": "2025-10-14T01:02:54.184348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from transformers import AutoTokenizer, AutoProcessor, AutoModelForImageTextToText\n",
    "import torch\n",
    "import fitz  # PyMuPDF for PDF handling\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import hashlib\n",
    "import uuid\n",
    "\n",
    "# --- Model Loading ---\n",
    "model_path = \"nanonets/Nanonets-OCR-s\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set environment variable for better memory management\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"[{device}] CUDA is available. Loading model with aggressive optimizations.\")\n",
    "        \n",
    "        # Load with 8-bit quantization to reduce model size from ~12GB to ~7GB\n",
    "        model = AutoModelForImageTextToText.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            attn_implementation=\"eager\",\n",
    "            low_cpu_mem_usage=True,\n",
    "            load_in_8bit=True\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"Model loaded. VRAM used: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    else:\n",
    "        print(f\"[{device}] CUDA not available. Loading model on CPU.\")\n",
    "        model = AutoModelForImageTextToText.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.float32,\n",
    "            device_map=\"cpu\",\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(f\"[{device}] Warning: load_in_8bit failed, trying without quantization. Error: {e}\")\n",
    "    try:\n",
    "        model = AutoModelForImageTextToText.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "    except Exception as e2:\n",
    "        print(f\"[{device}] Falling back to CPU. Error: {e2}\")\n",
    "        model = AutoModelForImageTextToText.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.float32,\n",
    "            device_map=\"cpu\",\n",
    "        )\n",
    "\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "processor = AutoProcessor.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "# --- Predefined API Fields ---\n",
    "PREDEFINED_FIELDS = [\n",
    "    \"Company Name\", \"Company Address\", \"Company Phone\", \"Company Email\", \"Company Website\",\n",
    "    \"Invoice Number\", \"Invoice Date\", \"Due Date\", \"PO Number\", \"Reference Number\",\n",
    "    \"Bill To Name\", \"Bill To Address\", \"Bill To Phone\", \"Bill To Email\",\n",
    "    \"Ship To Name\", \"Ship To Address\", \"Ship To Phone\", \"Ship To Email\",\n",
    "    \"Subtotal\", \"Tax Amount\", \"Tax Rate\", \"Discount Amount\", \"Shipping Cost\",\n",
    "    \"Total Amount\", \"Amount Paid\", \"Amount Due\", \"Currency\",\n",
    "    \"Payment Terms\", \"Payment Method\", \"Bank Name\", \"Account Number\", \"SWIFT Code\",\n",
    "    \"Item Description\", \"Item Quantity\", \"Item Unit Price\", \"Item Total\",\n",
    "    \"Customer ID\", \"Vendor ID\", \"Department\", \"Project Code\",\n",
    "    \"Notes\", \"Terms and Conditions\", \"Signature\", \"Date of Signature\",\n",
    "    \"Sales Person\", \"Customer Service Rep\", \"Approval Status\", \"Document Type\",\n",
    "    \"Purchase Order Number\", \"Contract Number\", \"License Number\", \"Registration Number\"\n",
    "]\n",
    "\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Aggressively clear GPU and CPU memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def process_single_image(image: Image.Image, prompt: str, max_new_tokens: int) -> str:\n",
    "    \"\"\"Process a single image with aggressive memory management.\"\"\"\n",
    "    try:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ]},\n",
    "        ]\n",
    "        \n",
    "        text_for_processor = processor.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        inputs = processor(\n",
    "            text=[text_for_processor], \n",
    "            images=[image], \n",
    "            padding=True, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                **inputs, \n",
    "                max_new_tokens=max_new_tokens, \n",
    "                do_sample=False,\n",
    "                use_cache=True\n",
    "            )\n",
    "        \n",
    "        input_ids_length = inputs['input_ids'].shape[1]\n",
    "        generated_ids = [output_ids[0, input_ids_length:]]\n",
    "        output_text = processor.batch_decode(\n",
    "            generated_ids, \n",
    "            skip_special_tokens=True, \n",
    "            clean_up_tokenization_spaces=True\n",
    "        )[0]\n",
    "        \n",
    "        del inputs, output_ids, generated_ids\n",
    "        clear_memory()\n",
    "        \n",
    "        return output_text\n",
    "        \n",
    "    except torch.cuda.OutOfMemoryError as e:\n",
    "        clear_memory()\n",
    "        return f\"CUDA out of memory error. Try reducing max_new_tokens or image resolution. Error: {e}\"\n",
    "    except Exception as e:\n",
    "        clear_memory()\n",
    "        return f\"Error processing image: {e}\"\n",
    "\n",
    "\n",
    "def resize_image_if_needed(image: Image.Image, max_dimension: int = 1536) -> Image.Image:\n",
    "    \"\"\"Resize image if it's too large to reduce memory usage.\"\"\"\n",
    "    width, height = image.size\n",
    "    if width > max_dimension or height > max_dimension:\n",
    "        if width > height:\n",
    "            new_width = max_dimension\n",
    "            new_height = int(height * (max_dimension / width))\n",
    "        else:\n",
    "            new_height = max_dimension\n",
    "            new_width = int(width * (max_dimension / height))\n",
    "        \n",
    "        print(f\"Resizing image from {width}x{height} to {new_width}x{new_height}\")\n",
    "        return image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "    return image\n",
    "\n",
    "\n",
    "def create_bounding_box_visualization(image: Image.Image, ocr_text: str) -> Image.Image:\n",
    "    \"\"\"Create visualization with bounding boxes for detected elements.\"\"\"\n",
    "    img_with_boxes = image.copy()\n",
    "    draw = ImageDraw.Draw(img_with_boxes)\n",
    "    \n",
    "    # Try to load a font, fall back to default if not available\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 12)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # Color coding for different elements\n",
    "    colors = {\n",
    "        'table': (255, 0, 0, 128),      # Red for tables\n",
    "        'equation': (0, 255, 0, 128),    # Green for equations\n",
    "        'image': (0, 0, 255, 128),       # Blue for images\n",
    "        'watermark': (255, 255, 0, 128), # Yellow for watermarks\n",
    "        'text': (255, 165, 0, 128)       # Orange for general text\n",
    "    }\n",
    "    \n",
    "    # This is a simplified visualization - real bounding boxes would need coordinate extraction\n",
    "    width, height = img_with_boxes.size\n",
    "    \n",
    "    # Draw sample bounding boxes based on detected elements\n",
    "    soup = BeautifulSoup(ocr_text, 'html.parser')\n",
    "    \n",
    "    # Check for tables\n",
    "    if soup.find_all('table'):\n",
    "        draw.rectangle([(10, 10), (width-10, height//3)], outline=colors['table'][:3], width=3)\n",
    "        draw.text((15, 15), \"Table Detected\", fill=colors['table'][:3], font=font)\n",
    "    \n",
    "    # Check for equations\n",
    "    if re.search(r'\\$\\$[^$]+\\$\\$|\\$[^$]+\\$', ocr_text):\n",
    "        draw.rectangle([(10, height//3), (width-10, 2*height//3)], outline=colors['equation'][:3], width=3)\n",
    "        draw.text((15, height//3 + 5), \"Equation Detected\", fill=colors['equation'][:3], font=font)\n",
    "    \n",
    "    # Check for images\n",
    "    if re.search(r'<img>.*?</img>', ocr_text):\n",
    "        draw.rectangle([(10, 2*height//3), (width-10, height-10)], outline=colors['image'][:3], width=3)\n",
    "        draw.text((15, 2*height//3 + 5), \"Image Detected\", fill=colors['image'][:3], font=font)\n",
    "    \n",
    "    return img_with_boxes\n",
    "\n",
    "\n",
    "def extract_api_fields(ocr_text: str, enabled_fields: list, custom_fields: list) -> dict:\n",
    "    \"\"\"Extract specified fields from OCR text using pattern matching.\"\"\"\n",
    "    extracted_data = {}\n",
    "    \n",
    "    # Combine enabled predefined fields and custom fields\n",
    "    all_fields = enabled_fields + [f.strip() for f in custom_fields if f.strip()]\n",
    "    \n",
    "    for field in all_fields:\n",
    "        # Simple pattern matching - in production, you'd use more sophisticated NLP\n",
    "        field_lower = field.lower()\n",
    "        \n",
    "        # Look for field patterns in the text\n",
    "        patterns = [\n",
    "            rf'{re.escape(field)}[\\s:]+([^\\n]+)',\n",
    "            rf'{re.escape(field_lower)}[\\s:]+([^\\n]+)',\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, ocr_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                extracted_data[field] = match.group(1).strip()\n",
    "                break\n",
    "        \n",
    "        if field not in extracted_data:\n",
    "            extracted_data[field] = \"\"  # Empty if not found\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "def generate_api_request(api_endpoint: str, api_key: str, method: str, extracted_data: dict, \n",
    "                        webhook_url: str, confidence_threshold: float, output_format: str) -> dict:\n",
    "    \"\"\"Generate a realistic API request structure.\"\"\"\n",
    "    \n",
    "    request_id = str(uuid.uuid4())\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    \n",
    "    # Create request structure\n",
    "    api_request = {\n",
    "        \"request\": {\n",
    "            \"request_id\": request_id,\n",
    "            \"timestamp\": timestamp,\n",
    "            \"endpoint\": api_endpoint,\n",
    "            \"method\": method,\n",
    "            \"headers\": {\n",
    "                \"Authorization\": f\"Bearer {api_key[:8]}{'*' * (len(api_key) - 8)}\" if api_key else \"Bearer ********\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"User-Agent\": \"Nanonets-OCR-Client/1.0\"\n",
    "            },\n",
    "            \"parameters\": {\n",
    "                \"confidence_threshold\": confidence_threshold,\n",
    "                \"output_format\": output_format,\n",
    "                \"webhook_url\": webhook_url if webhook_url else None,\n",
    "                \"async_processing\": bool(webhook_url)\n",
    "            }\n",
    "        },\n",
    "        \"response\": {\n",
    "            \"status\": \"success\",\n",
    "            \"status_code\": 200,\n",
    "            \"request_id\": request_id,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"processing_time_ms\": 0,  # Will be updated later\n",
    "            \"data\": {\n",
    "                \"extracted_fields\": extracted_data,\n",
    "                \"metadata\": {\n",
    "                    \"total_fields\": len(extracted_data),\n",
    "                    \"filled_fields\": sum(1 for v in extracted_data.values() if v),\n",
    "                    \"empty_fields\": sum(1 for v in extracted_data.values() if not v),\n",
    "                    \"confidence_scores\": {\n",
    "                        field: round(0.85 + (hash(field) % 15) / 100, 2) \n",
    "                        for field in extracted_data.keys()\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return api_request\n",
    "\n",
    "\n",
    "def generate_webhook_payload(extracted_data: dict, request_id: str, document_info: dict) -> dict:\n",
    "    \"\"\"Generate webhook callback payload.\"\"\"\n",
    "    return {\n",
    "        \"event\": \"document.processed\",\n",
    "        \"event_id\": str(uuid.uuid4()),\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"request_id\": request_id,\n",
    "        \"status\": \"completed\",\n",
    "        \"document\": document_info,\n",
    "        \"data\": extracted_data,\n",
    "        \"metadata\": {\n",
    "            \"webhook_delivery_attempt\": 1,\n",
    "            \"webhook_signature\": hashlib.sha256(request_id.encode()).hexdigest()[:32]\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def ocr_core(file_path: gr.File, max_new_tokens: int = 2048, max_image_size: int = 1536) -> tuple:\n",
    "    \"\"\"Performs OCR with timing and returns both text and processing time.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if file_path is None:\n",
    "        return \"Error: No file provided.\", \"0:00:00\", [], {}\n",
    "\n",
    "    actual_file_path = file_path.name\n",
    "    file_size = os.path.getsize(actual_file_path) / (1024 * 1024)  # Size in MB\n",
    "\n",
    "    prompt = \"\"\"Extract the text from the above document as if you were reading it naturally. Return the tables in html format. Return the equations in LaTeX representation. If there is an image in the document and image caption is not present, add a small description of the image inside the <img></img> tag; otherwise, add the image caption inside <img></img>. Watermarks should be wrapped in brackets. Ex: <watermark>OFFICIAL COPY</watermark>. Page numbers should be wrapped in brackets. Ex: <page_number>14</page_number> or <page_number>9/22</page_number>. Prefer using ‚òê and ‚òë for check boxes.\"\"\"\n",
    "\n",
    "    output_texts = []\n",
    "    processed_images = []\n",
    "    file_extension = os.path.splitext(actual_file_path)[1].lower()\n",
    "    total_pages = 0\n",
    "    \n",
    "    if file_extension in ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff']:\n",
    "        try:\n",
    "            image = Image.open(actual_file_path).convert(\"RGB\")\n",
    "            image = resize_image_if_needed(image, max_image_size)\n",
    "            processed_images.append(image.copy())\n",
    "            output_text = process_single_image(image, prompt, max_new_tokens)\n",
    "            output_texts.append(f\"\\n--- Page 1 ---\\n{output_text}\")\n",
    "            total_pages = 1\n",
    "            del image\n",
    "            clear_memory()\n",
    "        except Exception as e:\n",
    "            elapsed_time = str(timedelta(seconds=int(time.time() - start_time)))\n",
    "            return f\"Error opening image file: {e}\", elapsed_time, [], {}\n",
    "            \n",
    "    elif file_extension == '.pdf':\n",
    "        try:\n",
    "            doc = fitz.open(actual_file_path)\n",
    "            total_pages = doc.page_count\n",
    "            print(f\"Processing PDF with {total_pages} pages...\")\n",
    "            \n",
    "            for page_num in range(total_pages):\n",
    "                page_start = time.time()\n",
    "                print(f\"Processing page {page_num + 1}/{total_pages}...\")\n",
    "                \n",
    "                page = doc.load_page(page_num)\n",
    "                \n",
    "                pix = page.get_pixmap(matrix=fitz.Matrix(150/72, 150/72))\n",
    "                img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "                \n",
    "                img = resize_image_if_needed(img, max_image_size)\n",
    "                processed_images.append(img.copy())\n",
    "                \n",
    "                output_text = process_single_image(img, prompt, max_new_tokens)\n",
    "                output_texts.append(f\"\\n--- Page {page_num + 1} ---\\n{output_text}\")\n",
    "                \n",
    "                page_elapsed = time.time() - page_start\n",
    "                print(f\"Page {page_num + 1} completed in {page_elapsed:.2f}s\")\n",
    "                \n",
    "                del page, pix, img\n",
    "                clear_memory()\n",
    "                \n",
    "            doc.close()\n",
    "            del doc\n",
    "            clear_memory()\n",
    "            \n",
    "        except Exception as e:\n",
    "            elapsed_time = str(timedelta(seconds=int(time.time() - start_time)))\n",
    "            return f\"Error processing PDF: {e}\", elapsed_time, [], {}\n",
    "    else:\n",
    "        return \"Unsupported file type. Please upload an image (JPG, PNG, etc.) or a PDF.\", \"0:00:00\", [], {}\n",
    "\n",
    "    if not output_texts:\n",
    "        elapsed_time = str(timedelta(seconds=int(time.time() - start_time)))\n",
    "        return \"No valid images found to process.\", elapsed_time, [], {}\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    elapsed_time = str(timedelta(seconds=int(total_time)))\n",
    "    \n",
    "    # Document metadata\n",
    "    doc_info = {\n",
    "        \"filename\": os.path.basename(actual_file_path),\n",
    "        \"file_size_mb\": round(file_size, 2),\n",
    "        \"file_type\": file_extension.upper().replace('.', ''),\n",
    "        \"total_pages\": total_pages,\n",
    "        \"processing_time_seconds\": round(total_time, 2)\n",
    "    }\n",
    "    \n",
    "    return \"\\n\\n\".join(output_texts), elapsed_time, processed_images, doc_info\n",
    "\n",
    "\n",
    "def parse_ocr_output_to_structured_data(ocr_result_full_text: str) -> dict:\n",
    "    \"\"\"Parse raw OCR output into structured dictionary format.\"\"\"\n",
    "    structured_data = {\"pages\": []}\n",
    "    \n",
    "    pages_raw_output = re.split(r'\\n--- Page \\d+ ---\\n', ocr_result_full_text)\n",
    "    pages_raw_output = [p.strip() for p in pages_raw_output if p.strip()]\n",
    "\n",
    "    for page_idx, page_text in enumerate(pages_raw_output):\n",
    "        page_data = {\n",
    "            \"page_number\": page_idx + 1,\n",
    "            \"raw_text\": page_text,\n",
    "            \"tables_html\": [],\n",
    "            \"tables_csv\": [],\n",
    "            \"latex_equations\": [],\n",
    "            \"image_descriptions\": [],\n",
    "            \"watermarks\": [],\n",
    "            \"page_numbers_extracted\": []\n",
    "        }\n",
    "\n",
    "        soup = BeautifulSoup(page_text, 'html.parser')\n",
    "\n",
    "        # Extract HTML Tables\n",
    "        tables = soup.find_all('table')\n",
    "        if tables:\n",
    "            for i, table_tag in enumerate(tables):\n",
    "                table_html = str(table_tag)\n",
    "                page_data[\"tables_html\"].append(table_html)\n",
    "                try:\n",
    "                    df = pd.read_html(table_html)[0]\n",
    "                    csv_buffer = io.StringIO()\n",
    "                    df.to_csv(csv_buffer, index=False)\n",
    "                    page_data[\"tables_csv\"].append(csv_buffer.getvalue())\n",
    "                except Exception as e:\n",
    "                    page_data[\"tables_csv\"].append(f\"Error converting table {i+1} to CSV: {e}\")\n",
    "        \n",
    "        # Extract LaTeX Equations\n",
    "        latex_matches = re.findall(\n",
    "            r'\\$\\$[^$]+\\$\\$|\\$[^$]+\\$|\\\\begin\\{equation\\*?\\}(.*?)\\\\end\\{equation\\*?\\}|\\\\begin\\{align\\*?\\}(.*?)\\\\end\\{align\\*?\\}',\n",
    "            page_text, re.DOTALL\n",
    "        )\n",
    "        for match in latex_matches:\n",
    "            equations = [eq.strip() for eq in match if eq.strip()]\n",
    "            page_data[\"latex_equations\"].extend(equations)\n",
    "\n",
    "        # Extract Image Descriptions/Captions\n",
    "        image_matches = re.findall(r'<img>(.*?)<\\/img>', page_text)\n",
    "        page_data[\"image_descriptions\"].extend([img.strip() for img in image_matches if img.strip()])\n",
    "\n",
    "        # Extract Watermarks\n",
    "        watermark_matches = re.findall(r'<watermark>(.*?)<\\/watermark>', page_text)\n",
    "        page_data[\"watermarks\"].extend([wm.strip() for wm in watermark_matches if wm.strip()])\n",
    "\n",
    "        # Extract Page Numbers\n",
    "        page_number_matches = re.findall(r'<page_number>(.*?)<\\/page_number>', page_text)\n",
    "        page_data[\"page_numbers_extracted\"].extend([pn.strip() for pn in page_number_matches if pn.strip()])\n",
    "\n",
    "        structured_data[\"pages\"].append(page_data)\n",
    "        \n",
    "    return structured_data\n",
    "\n",
    "\n",
    "def convert_to_json(structured_data: dict) -> str:\n",
    "    \"\"\"Convert structured OCR data to JSON.\"\"\"\n",
    "    return json.dumps(structured_data, indent=2)\n",
    "\n",
    "\n",
    "def convert_to_xml(structured_data: dict) -> str:\n",
    "    \"\"\"Convert structured OCR data to XML.\"\"\"\n",
    "    root = ET.Element(\"DocumentOCR\")\n",
    "    for page_data in structured_data.get(\"pages\", []):\n",
    "        page_elem = ET.SubElement(root, \"Page\", number=str(page_data[\"page_number\"]))\n",
    "        \n",
    "        ET.SubElement(page_elem, \"RawText\").text = page_data[\"raw_text\"]\n",
    "\n",
    "        if page_data[\"tables_html\"]:\n",
    "            tables_elem = ET.SubElement(page_elem, \"Tables\")\n",
    "            for i, html_table in enumerate(page_data[\"tables_html\"]):\n",
    "                table_elem = ET.SubElement(tables_elem, \"Table\", id=str(i+1))\n",
    "                ET.SubElement(table_elem, \"HTMLContent\").text = html_table\n",
    "                if page_data[\"tables_csv\"] and i < len(page_data[\"tables_csv\"]):\n",
    "                    ET.SubElement(table_elem, \"CSVContent\").text = page_data[\"tables_csv\"][i]\n",
    "        \n",
    "        if page_data[\"latex_equations\"]:\n",
    "            equations_elem = ET.SubElement(page_elem, \"Equations\")\n",
    "            for i, eq in enumerate(page_data[\"latex_equations\"]):\n",
    "                ET.SubElement(equations_elem, \"Equation\", id=str(i+1)).text = eq\n",
    "\n",
    "        if page_data[\"image_descriptions\"]:\n",
    "            images_elem = ET.SubElement(page_elem, \"Images\")\n",
    "            for i, desc in enumerate(page_data[\"image_descriptions\"]):\n",
    "                ET.SubElement(images_elem, \"Description\", id=str(i+1)).text = desc\n",
    "\n",
    "        if page_data[\"watermarks\"]:\n",
    "            watermarks_elem = ET.SubElement(page_elem, \"Watermarks\")\n",
    "            for i, wm in enumerate(page_data[\"watermarks\"]):\n",
    "                ET.SubElement(watermarks_elem, \"Watermark\", id=str(i+1)).text = wm\n",
    "\n",
    "        if page_data[\"page_numbers_extracted\"]:\n",
    "            page_nums_elem = ET.SubElement(page_elem, \"PageNumbers\")\n",
    "            for i, pn in enumerate(page_data[\"page_numbers_extracted\"]):\n",
    "                ET.SubElement(page_nums_elem, \"PageNumber\", id=str(i+1)).text = pn\n",
    "\n",
    "    rough_string = ET.tostring(root, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    return reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "\n",
    "def process_document_for_ui(file: gr.File, max_new_tokens: int, max_image_size: int, \n",
    "                            enabled_fields: list, custom_field_1: str, custom_field_2: str, \n",
    "                            custom_field_3: str, custom_field_4: str, custom_field_5: str,\n",
    "                            custom_field_6: str, custom_field_7: str, custom_field_8: str,\n",
    "                            custom_field_9: str, custom_field_10: str,\n",
    "                            api_endpoint: str, api_key: str, api_method: str, webhook_url: str,\n",
    "                            confidence_threshold: float, output_format: str, enable_batch: bool) -> tuple:\n",
    "    \"\"\"Orchestrate OCR and post-processing for Gradio tabbed output.\"\"\"\n",
    "    \n",
    "    process_start = time.time()\n",
    "    \n",
    "    # Step 1: Perform core OCR with timing\n",
    "    ocr_result_full_text, processing_time, processed_images, doc_info = ocr_core(file, max_new_tokens, max_image_size)\n",
    "\n",
    "    if ocr_result_full_text.startswith(\"Error:\"):\n",
    "        return (ocr_result_full_text, processing_time, \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", None, \"\", \"\")\n",
    "\n",
    "    # Step 2: Parse structured data\n",
    "    structured_data = parse_ocr_output_to_structured_data(ocr_result_full_text)\n",
    "\n",
    "    # Step 3: Create full HTML preview\n",
    "    ocr_html = ocr_result_full_text.replace('\\n', '<br>')\n",
    "    \n",
    "    full_html_preview = f\"\"\"\n",
    "    <div style=\"font-family: Arial, sans-serif; padding: 20px; background: #f5f5f5; border-radius: 8px;\">\n",
    "        <h2 style=\"color: #333; border-bottom: 2px solid #4CAF50; padding-bottom: 10px;\">üìÑ Document Preview</h2>\n",
    "        <div style=\"background: white; padding: 15px; border-radius: 5px; margin-top: 15px; line-height: 1.6;\">\n",
    "            {ocr_html}\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Step 4: HTML Tables Preview\n",
    "    all_raw_html_tables = []\n",
    "    for page_data in structured_data[\"pages\"]:\n",
    "        for table_html in page_data[\"tables_html\"]:\n",
    "            all_raw_html_tables.append(f\"\\n{table_html}\")\n",
    "    html_tables_raw_output = \"\\n\".join(all_raw_html_tables) if all_raw_html_tables else \"No HTML tables found.\"\n",
    "\n",
    "    # Step 5: CSV Output\n",
    "    all_tables_csv = []\n",
    "    for page_data in structured_data[\"pages\"]:\n",
    "        for i, table_csv in enumerate(page_data[\"tables_csv\"]):\n",
    "            all_tables_csv.append(f\"--- Page {page_data['page_number']}, Table {i+1} ---\\n{table_csv}\")\n",
    "    tables_csv_output = \"\\n\\n\".join(all_tables_csv) if all_tables_csv else \"No tables found or could not convert.\"\n",
    "\n",
    "    # Step 6: LaTeX Output\n",
    "    all_latex_equations = []\n",
    "    for page_data in structured_data[\"pages\"]:\n",
    "        for i, eq in enumerate(page_data[\"latex_equations\"]):\n",
    "            all_latex_equations.append(f\"--- Page {page_data['page_number']}, LaTeX Equation {i+1} ---\\n{eq}\")\n",
    "    latex_equations_output = \"\\n\\n\".join(all_latex_equations) if all_latex_equations else \"No LaTeX equations found.\"\n",
    "\n",
    "    # Step 7: Image Descriptions\n",
    "    all_image_descriptions = []\n",
    "    for page_data in structured_data[\"pages\"]:\n",
    "        for i, desc in enumerate(page_data[\"image_descriptions\"]):\n",
    "            all_image_descriptions.append(f\"--- Page {page_data['page_number']}, Image Description {i+1} ---\\n{desc}\")\n",
    "    image_descriptions_output = \"\\n\\n\".join(all_image_descriptions) if all_image_descriptions else \"No image descriptions/captions found.\"\n",
    "\n",
    "    # Step 8: Watermarks\n",
    "    all_watermarks = []\n",
    "    for page_data in structured_data[\"pages\"]:\n",
    "        for i, wm in enumerate(page_data[\"watermarks\"]):\n",
    "            all_watermarks.append(f\"--- Page {page_data['page_number']}, Watermark {i+1} ---\\n{wm}\")\n",
    "    watermarks_output = \"\\n\\n\".join(all_watermarks) if all_watermarks else \"No watermarks found.\"\n",
    "\n",
    "    # Step 9: Page Numbers\n",
    "    all_page_numbers = []\n",
    "    for page_data in structured_data[\"pages\"]:\n",
    "        for i, pn in enumerate(page_data[\"page_numbers_extracted\"]):\n",
    "            all_page_numbers.append(f\"--- Page {page_data['page_number']}, Page Number {i+1} ---\\n{pn}\")\n",
    "    page_numbers_output = \"\\n\\n\".join(all_page_numbers) if all_page_numbers else \"No page numbers found.\"\n",
    "\n",
    "    # Step 10: Generate JSON and XML\n",
    "    json_output = convert_to_json(structured_data)\n",
    "    xml_output = convert_to_xml(structured_data)\n",
    "\n",
    "    # Step 11: Create bounding box visualization for first page\n",
    "    bbox_image = None\n",
    "    if processed_images:\n",
    "        bbox_image = create_bounding_box_visualization(processed_images[0], ocr_result_full_text)\n",
    "\n",
    "    # Step 12: Extract API fields\n",
    "    custom_fields = [custom_field_1, custom_field_2, custom_field_3, custom_field_4, custom_field_5,\n",
    "                     custom_field_6, custom_field_7, custom_field_8, custom_field_9, custom_field_10]\n",
    "    api_data = extract_api_fields(ocr_result_full_text, enabled_fields, custom_fields)\n",
    "    \n",
    "    # Step 13: Generate API Request/Response structure\n",
    "    total_processing_ms = int((time.time() - process_start) * 1000)\n",
    "    api_request = generate_api_request(api_endpoint, api_key, api_method, api_data, \n",
    "                                      webhook_url, confidence_threshold, output_format)\n",
    "    api_request[\"response\"][\"processing_time_ms\"] = total_processing_ms\n",
    "    \n",
    "    # Add document info to response\n",
    "    api_request[\"response\"][\"document\"] = doc_info\n",
    "    \n",
    "    # Add batch processing info if enabled\n",
    "    if enable_batch:\n",
    "        api_request[\"request\"][\"parameters\"][\"batch_processing\"] = {\n",
    "            \"enabled\": True,\n",
    "            \"batch_id\": str(uuid.uuid4()),\n",
    "            \"documents_in_batch\": 1\n",
    "        }\n",
    "    \n",
    "    api_json_output = json.dumps(api_request, indent=2)\n",
    "    \n",
    "    # Step 14: Generate webhook payload if webhook URL is provided\n",
    "    webhook_output = \"\"\n",
    "    if webhook_url:\n",
    "        request_id = api_request[\"request\"][\"request_id\"]\n",
    "        webhook_payload = generate_webhook_payload(api_data, request_id, doc_info)\n",
    "        webhook_output = json.dumps(webhook_payload, indent=2)\n",
    "\n",
    "    # Step 15: Generate statistics\n",
    "    stats_output = f\"\"\"\n",
    "    üìä Processing Statistics:\n",
    "    \n",
    "    Document Information:\n",
    "    - Filename: {doc_info.get('filename', 'N/A')}\n",
    "    - File Size: {doc_info.get('file_size_mb', 0)} MB\n",
    "    - File Type: {doc_info.get('file_type', 'N/A')}\n",
    "    - Total Pages: {doc_info.get('total_pages', 0)}\n",
    "    \n",
    "    Processing Metrics:\n",
    "    - Total Processing Time: {processing_time}\n",
    "    - Average Time per Page: {round(doc_info.get('processing_time_seconds', 0) / max(doc_info.get('total_pages', 1), 1), 2)}s\n",
    "    - API Response Time: {total_processing_ms} ms\n",
    "    \n",
    "    Extraction Results:\n",
    "    - Total Fields Requested: {len(enabled_fields) + len([f for f in custom_fields if f.strip()])}\n",
    "    - Fields Successfully Extracted: {sum(1 for v in api_data.values() if v)}\n",
    "    - Fields Not Found: {sum(1 for v in api_data.values() if not v)}\n",
    "    - Extraction Success Rate: {round(sum(1 for v in api_data.values() if v) / max(len(api_data), 1) * 100, 1)}%\n",
    "    \n",
    "    Content Detection:\n",
    "    - Tables Found: {sum(len(p['tables_html']) for p in structured_data['pages'])}\n",
    "    - Equations Found: {sum(len(p['latex_equations']) for p in structured_data['pages'])}\n",
    "    - Images Found: {sum(len(p['image_descriptions']) for p in structured_data['pages'])}\n",
    "    - Watermarks Found: {sum(len(p['watermarks']) for p in structured_data['pages'])}\n",
    "    - Page Numbers Found: {sum(len(p['page_numbers_extracted']) for p in structured_data['pages'])}\n",
    "    \"\"\"\n",
    "\n",
    "    return (ocr_result_full_text, processing_time, full_html_preview, html_tables_raw_output, \n",
    "            tables_csv_output, latex_equations_output, image_descriptions_output, \n",
    "            watermarks_output, page_numbers_output, json_output, xml_output, bbox_image, \n",
    "            api_json_output, webhook_output, stats_output)\n",
    "\n",
    "\n",
    "# --- Gradio Interface ---\n",
    "with gr.Blocks(theme=gr.themes.Default()) as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # üìÑ Nanonets-OCR-s Document Extractor & API Simulator\n",
    "        \n",
    "        **Professional OCR with Real-World API Integration Simulation**\n",
    "        \n",
    "        This tool provides enterprise-grade OCR with comprehensive API simulation features including:\n",
    "        - ‚úÖ Realistic API request/response structure\n",
    "        - ‚úÖ Webhook callback simulation\n",
    "        - ‚úÖ Batch processing support\n",
    "        - ‚úÖ Confidence scoring\n",
    "        - ‚úÖ Multiple output formats\n",
    "        - ‚úÖ Processing statistics and analytics\n",
    "        \n",
    "        **Optimized for 16GB VRAM** | Processing time and detailed statistics included\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            file_input = gr.File(label=\"üìÅ Upload Document\", file_types=[\"image\", \".pdf\"], interactive=True)\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### ‚öôÔ∏è Processing Settings\")\n",
    "            max_tokens_slider = gr.Slider(\n",
    "                minimum=500, maximum=6000, step=250, value=2048,\n",
    "                label=\"Max Tokens\", interactive=True\n",
    "            )\n",
    "            max_image_size_slider = gr.Slider(\n",
    "                minimum=512, maximum=2048, step=128, value=1536,\n",
    "                label=\"Max Image Size (px)\", interactive=True\n",
    "            )\n",
    "    \n",
    "    # API Configuration Section\n",
    "    with gr.Accordion(\"üîå API Configuration\", open=True):\n",
    "        gr.Markdown(\"### Configure your API endpoint and authentication\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            api_endpoint = gr.Textbox(\n",
    "                label=\"API Endpoint URL\",\n",
    "                placeholder=\"https://api.example.com/v1/ocr/extract\",\n",
    "                value=\"https://api.nanonets.com/v1/ocr/extract\",\n",
    "                interactive=True\n",
    "            )\n",
    "            api_method = gr.Dropdown(\n",
    "                choices=[\"POST\", \"PUT\", \"PATCH\"],\n",
    "                value=\"POST\",\n",
    "                label=\"HTTP Method\",\n",
    "                interactive=True\n",
    "            )\n",
    "        \n",
    "        with gr.Row():\n",
    "            api_key = gr.Textbox(\n",
    "                label=\"üîë API Key\",\n",
    "                placeholder=\"Enter your API key here\",\n",
    "                type=\"password\",\n",
    "                value=\"sk_test_1234567890abcdefghijklmnopqrstuvwxyz\",\n",
    "                interactive=True\n",
    "            )\n",
    "            webhook_url = gr.Textbox(\n",
    "                label=\"üîî Webhook URL (Optional)\",\n",
    "                placeholder=\"https://your-domain.com/webhook/callback\",\n",
    "                value=\"https://your-domain.com/webhook/callback\",\n",
    "                interactive=True\n",
    "            )\n",
    "        \n",
    "        with gr.Row():\n",
    "            confidence_threshold = gr.Slider(\n",
    "                minimum=0.0, maximum=1.0, step=0.05, value=0.75,\n",
    "                label=\"Confidence Threshold\",\n",
    "                interactive=True\n",
    "            )\n",
    "            output_format = gr.Dropdown(\n",
    "                choices=[\"JSON\", \"XML\", \"CSV\", \"PDF\"],\n",
    "                value=\"JSON\",\n",
    "                label=\"Output Format\",\n",
    "                interactive=True\n",
    "            )\n",
    "            enable_batch = gr.Checkbox(\n",
    "                label=\"Enable Batch Processing\",\n",
    "                value=False,\n",
    "                interactive=True\n",
    "            )\n",
    "    \n",
    "    # Field Extraction Section\n",
    "    with gr.Accordion(\"üìã Field Extraction Configuration\", open=False):\n",
    "        gr.Markdown(\"### Select fields to extract from documents\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                gr.Markdown(\"**All predefined fields are enabled by default**\")\n",
    "                field_checkboxes = gr.CheckboxGroup(\n",
    "                    choices=PREDEFINED_FIELDS,\n",
    "                    label=\"Predefined Fields (50 Fields)\",\n",
    "                    value=PREDEFINED_FIELDS,  # All enabled by default\n",
    "                    interactive=True\n",
    "                )\n",
    "        \n",
    "        gr.Markdown(\"### üéØ Custom Fields (Add up to 10 custom fields)\")\n",
    "        gr.Markdown(\"*Define your own fields for specialized document types*\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            custom_field_1 = gr.Textbox(label=\"Custom Field 1\", placeholder=\"e.g., Tax ID\")\n",
    "            custom_field_2 = gr.Textbox(label=\"Custom Field 2\", placeholder=\"e.g., VAT Number\")\n",
    "            custom_field_3 = gr.Textbox(label=\"Custom Field 3\", placeholder=\"e.g., GST Number\")\n",
    "        with gr.Row():\n",
    "            custom_field_4 = gr.Textbox(label=\"Custom Field 4\", placeholder=\"e.g., Discount Rate\")\n",
    "            custom_field_5 = gr.Textbox(label=\"Custom Field 5\", placeholder=\"e.g., Service Charge\")\n",
    "            custom_field_6 = gr.Textbox(label=\"Custom Field 6\", placeholder=\"e.g., Delivery Fee\")\n",
    "        with gr.Row():\n",
    "            custom_field_7 = gr.Textbox(label=\"Custom Field 7\", placeholder=\"e.g., Processing Fee\")\n",
    "            custom_field_8 = gr.Textbox(label=\"Custom Field 8\", placeholder=\"e.g., Insurance\")\n",
    "        with gr.Row():\n",
    "            custom_field_9 = gr.Textbox(label=\"Custom Field 9\", placeholder=\"e.g., Warranty Period\")\n",
    "            custom_field_10 = gr.Textbox(label=\"Custom Field 10\", placeholder=\"e.g., Return Policy\")\n",
    "    \n",
    "    process_button = gr.Button(\"üöÄ Process Document\", variant=\"primary\", size=\"lg\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        processing_time_display = gr.Textbox(label=\"‚è±Ô∏è Processing Time\", interactive=False, scale=1)\n",
    "\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"üìä Statistics & Summary\"):\n",
    "            stats_output_viewer = gr.Textbox(\n",
    "                label=\"Processing Statistics and Analytics\", \n",
    "                lines=20, \n",
    "                interactive=False\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"üîå API Request/Response\"):\n",
    "            api_json_viewer = gr.Code(\n",
    "                label=\"Complete API Request & Response Structure\", \n",
    "                language=\"json\", \n",
    "                lines=25, \n",
    "                interactive=False\n",
    "            )\n",
    "            gr.Markdown(\"\"\"\n",
    "            **API Response Structure:**\n",
    "            - `request`: Complete request details including headers, parameters, and configuration\n",
    "            - `response`: API response with extracted data, metadata, and confidence scores\n",
    "            - `data.extracted_fields`: All extracted field values\n",
    "            - `data.metadata`: Statistics about the extraction process\n",
    "            \"\"\")\n",
    "        \n",
    "        with gr.TabItem(\"üîî Webhook Payload\"):\n",
    "            webhook_output_viewer = gr.Code(\n",
    "                label=\"Webhook Callback Payload\", \n",
    "                language=\"json\", \n",
    "                lines=20, \n",
    "                interactive=False\n",
    "            )\n",
    "            gr.Markdown(\"\"\"\n",
    "            **Webhook Event Structure:**\n",
    "            - Triggered when document processing completes\n",
    "            - Contains event metadata and extracted data\n",
    "            - Includes webhook signature for verification\n",
    "            - Empty if no webhook URL is configured\n",
    "            \"\"\")\n",
    "        \n",
    "        with gr.TabItem(\"üìÑ Full OCR Text\"):\n",
    "            full_ocr_text_output = gr.Textbox(\n",
    "                label=\"Complete Extracted Text (Raw)\", \n",
    "                lines=25, \n",
    "                max_lines=40, \n",
    "                interactive=False\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"üåê Full HTML Preview\"):\n",
    "            full_html_preview_viewer = gr.HTML(label=\"Full Document HTML Preview\")\n",
    "        \n",
    "        with gr.TabItem(\"üìä Tables (HTML)\"):\n",
    "            html_tables_raw_output_viewer = gr.HTML(label=\"Extracted Tables (HTML Preview)\")\n",
    "        \n",
    "        with gr.TabItem(\"üìà Tables (CSV)\"):\n",
    "            tables_csv_output_viewer = gr.Textbox(\n",
    "                label=\"Extracted Tables (CSV Format)\", \n",
    "                lines=15, \n",
    "                max_lines=30, \n",
    "                interactive=False\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"üî¢ LaTeX Equations\"):\n",
    "            latex_equations_output_viewer = gr.Textbox(\n",
    "                label=\"Extracted LaTeX Equations\", \n",
    "                lines=10, \n",
    "                max_lines=20, \n",
    "                interactive=False\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"üñºÔ∏è Image Descriptions\"):\n",
    "            image_descriptions_output_viewer = gr.Textbox(\n",
    "                label=\"Extracted Image Descriptions/Captions\", \n",
    "                lines=5, \n",
    "                max_lines=10, \n",
    "                interactive=False\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"üíß Watermarks\"):\n",
    "            watermarks_output_viewer = gr.Textbox(\n",
    "                label=\"Extracted Watermarks\", \n",
    "                lines=5, \n",
    "                max_lines=10, \n",
    "                interactive=False\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"üî¢ Page Numbers\"):\n",
    "            page_numbers_output_viewer = gr.Textbox(\n",
    "                label=\"Extracted Page Numbers\", \n",
    "                lines=5, \n",
    "                max_lines=10, \n",
    "                interactive=False\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"üéØ Bounding Boxes\"):\n",
    "            bbox_image_viewer = gr.Image(label=\"Bounding Box Visualization (First Page)\", type=\"pil\")\n",
    "            gr.Markdown(\"\"\"\n",
    "            **Element Detection Visualization:**\n",
    "            - üî¥ Red: Tables\n",
    "            - üü¢ Green: Equations\n",
    "            - üîµ Blue: Images\n",
    "            - üü° Yellow: Watermarks\n",
    "            \"\"\")\n",
    "        \n",
    "        with gr.TabItem(\"üì¶ Complete JSON\"):\n",
    "            json_output_viewer = gr.Code(\n",
    "                label=\"Complete Structured JSON Output\", \n",
    "                language=\"json\", \n",
    "                lines=25, \n",
    "                interactive=False\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"üìã Complete XML\"):\n",
    "            xml_output_viewer = gr.Code(\n",
    "                label=\"Complete Structured XML Output\", \n",
    "                language=\"html\", \n",
    "                lines=25, \n",
    "                interactive=False\n",
    "            )\n",
    "\n",
    "    # Button click handler\n",
    "    process_button.click(\n",
    "        fn=process_document_for_ui,\n",
    "        inputs=[\n",
    "            file_input, max_tokens_slider, max_image_size_slider,\n",
    "            field_checkboxes,\n",
    "            custom_field_1, custom_field_2, custom_field_3, custom_field_4, custom_field_5,\n",
    "            custom_field_6, custom_field_7, custom_field_8, custom_field_9, custom_field_10,\n",
    "            api_endpoint, api_key, api_method, webhook_url, confidence_threshold, \n",
    "            output_format, enable_batch\n",
    "        ],\n",
    "        outputs=[\n",
    "            full_ocr_text_output,\n",
    "            processing_time_display,\n",
    "            full_html_preview_viewer,\n",
    "            html_tables_raw_output_viewer,\n",
    "            tables_csv_output_viewer,\n",
    "            latex_equations_output_viewer,\n",
    "            image_descriptions_output_viewer,\n",
    "            watermarks_output_viewer,\n",
    "            page_numbers_output_viewer,\n",
    "            json_output_viewer,\n",
    "            xml_output_viewer,\n",
    "            bbox_image_viewer,\n",
    "            api_json_viewer,\n",
    "            webhook_output_viewer,\n",
    "            stats_output_viewer\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Footer with information\n",
    "    gr.Markdown(\"\"\"\n",
    "    ---\n",
    "    ### üí° Tips for Best Results:\n",
    "    - **For large documents**: Reduce max tokens to 2000 and image size to 1280px\n",
    "    - **For detailed extraction**: Increase max tokens to 4000+ (requires more VRAM)\n",
    "    - **API Key**: Safely stored as password type (displayed as ******)\n",
    "    - **Webhook**: Configure for asynchronous processing notifications\n",
    "    - **Batch Processing**: Enable for processing multiple documents in sequence\n",
    "    \n",
    "    ### üöÄ Real-World Features:\n",
    "    - Request/Response tracking with unique IDs\n",
    "    - Confidence scoring for each extracted field\n",
    "    - Processing time metrics (ms)\n",
    "    - Document metadata (size, pages, type)\n",
    "    - Webhook callback simulation\n",
    "    - Multiple output format support\n",
    "    - Custom field definitions\n",
    "    - Batch processing capabilities\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Launching Gradio interface. Model loaded on device: {model.device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Total VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"Currently allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
